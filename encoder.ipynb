{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8fd0db9",
   "metadata": {},
   "source": [
    "总结：首先是Input_embedding和positional_encoding 是Transformer中的一环\n",
    "EncoderLayer包含MultiHeadAttention\n",
    "https://blog.csdn.net/weixin_44613415/article/details/139848359"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c567925a",
   "metadata": {},
   "source": [
    "## 下面是Transformer的class\n",
    "已知这里会有Input_embedding和Positional_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f62c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fc86123",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):#维度是奇数也不会报错\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super().__init__()#继承父类nn.Module\n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        # 只考虑偶数位置，确保 div_term 的长度匹配\n",
    "        div_term = torch.exp(2 * torch.arange(0, (d_model + 1) // 2).float()  * -(math.log(10000.0) / d_model))\n",
    "        #其中2 * torch.arange(0, (d_model + 1) // 2).float()是2i\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term[:d_model // 2]) \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))#pe是[batch_size, seq_length, d_model]，注册后会成为self.pe\n",
    "\n",
    "    def forward(self, x):#这里的x是[batch_size, seq_length, d_model]\n",
    "        return x + self.pe[:, :x.size(1)]#也可以尝试下除了相加的方式，但是感觉乘法的话就会有权重为0的可能性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4df05750",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):#x是[batch_size, seq_length, d_model]\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()#继承父类nn.Module\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = self.d_model//self.num_heads #因为要整除\n",
    "        self.Qw = nn.Linear(d_model, d_model)#加载Q权重\n",
    "        self.Kw = nn.Linear(d_model, d_model)#加载K权重\n",
    "        self.Vw = nn.Linear(d_model, d_model)#加载V权重\n",
    "        self.Ow = nn.Linear(d_model, d_model)#加载V权重\n",
    "        \n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "    #把第一列和第二列交换，也就是seq_length和self.num_heads\n",
    "    #变成了(batch_size, self.num_heads, seq_length, self.d_k)\n",
    "\n",
    "    def concat_heads(self, x):\n",
    "        batch_size, num_heads, seq_length, d_k = x.size()\n",
    "        return x.transpose(2,1).reshape(batch_size, seq_length, self.d_model)\n",
    "    \n",
    "    def dot_attention(self, Q, K, V):\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)#首先是K转置，所以要交换最后两列，矩阵相乘\n",
    "        #得到格式为[batch_size,num_heads,seq_length,seq_length]\n",
    "\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)#对最后一维做softmax\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output#得到了(batch_size, self.num_heads, seq_length, self.d_k)\n",
    "\n",
    "    \n",
    "    def forward(self,Q,K,V):#首先第一步是分头，把d_model分解成num_heads\n",
    "        Qa=self.split_heads(self.Qw(Q))\n",
    "        Ka=self.split_heads(self.Kw(K))\n",
    "        Va=self.split_heads(self.Vw(V))\n",
    "        attn_output = self.dot_attention(Qa, Ka, Va)\n",
    "        output= self.Ow(self.concat_heads(attn_output))\n",
    "        return output\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d1b8a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):# 感觉前馈层能做很多，加上dropout吧\n",
    "    def __init__(self, d_model,d_hidden,is_drop = True, drop = 0.1):\n",
    "        super().__init__()#继承父类nn.Module\n",
    "        self.W1 = nn.Linear(d_model, d_hidden)\n",
    "        self.W2 = nn.Linear(d_hidden, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(drop)\n",
    "        self.is_drop=is_drop\n",
    "    \n",
    "    def forward(self, x,):\n",
    "        x = self.relu(self.W1(x))\n",
    "        if self.is_drop:\n",
    "            x=self.dropout(x)\n",
    "        return self.W2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "712ef3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self,d_model, num_heads, d_hidden,is_drop = True, drop = 0.1):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.feed_forward = FeedForward(d_model,d_hidden,is_drop, drop)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_output = self.attn(x, x, x)\n",
    "        x = self.norm1(x + attn_output)\n",
    "        f_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + f_output)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd6d83f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        #Embedding层输入（vocab表，embedding的维度），输出（句子的长度，embedding的维度）\n",
    "        self.encoder_input_embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        #PositionalEncoding层输入（最大长度，嵌入维度）先把位置编码固定了\n",
    "        self.positional_encoding = PositionalEncoding(max_seq_length, embedding_dim)#位置编码的维度和嵌入维度通常要一样，因为要相加在一起\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7276d249",
   "metadata": {},
   "source": [
    "# 测试部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "679e2768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始句子: ['I', 'like', 'to', 'learn', 'deep', 'learning', 'with', 'PyTorch']\n",
      "句子索引: tensor([[0, 1, 2, 3, 4, 5, 6, 7]])\n",
      "嵌入向量形状: torch.Size([1, 8, 6])\n",
      "嵌入向量:\n",
      " tensor([[[-0.7101,  0.9343,  0.2147,  1.0305,  0.5206,  0.9302],\n",
      "         [ 0.9444,  0.9065,  1.9526, -0.1270,  0.5217,  0.0225],\n",
      "         [-0.8404, -1.4494,  0.6397,  0.3126,  0.9880,  0.8974],\n",
      "         [-1.4842,  0.5062,  0.8308,  1.5225,  0.7169,  0.4613],\n",
      "         [ 0.0235,  0.1256, -0.9946,  1.5360,  0.0793, -0.8803],\n",
      "         [ 1.0161, -1.5865, -0.0037,  0.7971, -0.4155,  0.5050],\n",
      "         [ 0.7089,  2.2143, -0.5585,  0.9090,  0.5003,  0.9560],\n",
      "         [ 0.0380, -0.5979, -0.6246, -0.8070, -0.2228,  0.5255]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## tips：下面是关于embedding层的测试\n",
    "# 定义词汇表（Vocabulary）\n",
    "vocab = {'I': 0, 'like': 1, 'to': 2, 'learn': 3, 'deep': 4, 'learning': 5, 'with': 6, 'PyTorch': 7}\n",
    "vocab_size = len(vocab)\n",
    "# 定义句子\n",
    "sentence = ['I', 'like', 'to', 'learn', 'deep', 'learning', 'with', 'PyTorch']\n",
    "\n",
    "# 将句子中的单词映射为索引序列\n",
    "sentence_indices = [vocab[word] for word in sentence]\n",
    "# 将索引序列转换为张量，同事\n",
    "sentence_tensor = torch.tensor(sentence_indices).unsqueeze(0) \n",
    "# 定义 nn.Embedding 层\n",
    "embedding_dim = 6\n",
    "embedding_layer = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "# 使用 nn.Embedding 将索引序列转换为嵌入向量\n",
    "embedded_sentence = embedding_layer(sentence_tensor)\n",
    "# 打印结果\n",
    "print(\"原始句子:\", sentence)\n",
    "print(\"句子索引:\", sentence_tensor )\n",
    "print(\"嵌入向量形状:\", embedded_sentence.shape)  # (sequence_length, embedding_dim)\n",
    "print(\"嵌入向量:\\n\", embedded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fb5a03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7101,  1.9343,  0.2147,  2.0305,  0.5206,  1.9302],\n",
       "         [ 1.7858,  1.4468,  1.9990,  0.8719,  0.5238,  1.0225],\n",
       "         [ 0.0689, -1.8655,  0.7324,  1.3083,  0.9924,  1.8974],\n",
       "         [-1.3431, -0.4838,  0.9696,  2.5129,  0.7233,  1.4612],\n",
       "         [-0.7333, -0.5280, -0.8100,  2.5188,  0.0879,  0.1196],\n",
       "         [ 0.0572, -1.3028,  0.2263,  1.7703, -0.4047,  1.5049],\n",
       "         [ 0.4295,  3.1745, -0.2836,  1.8705,  0.5132,  1.9559],\n",
       "         [ 0.6950,  0.1560, -0.3054,  0.1407, -0.2077,  1.5254]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## tips：下面是关于positional embedding层的测试\n",
    "max_seq_length = 10\n",
    "d_model = 6\n",
    "pe = torch.zeros(max_seq_length, d_model)\n",
    "position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "# 只考虑偶数位置，确保 div_term 的长度匹配\n",
    "div_term = torch.exp(2*torch.arange(0, (d_model + 1) // 2).float()  * -(math.log(10000.0) / d_model))\n",
    "# print(position)\n",
    "# print(torch.arange(0, (d_model + 1) // 2).float(), div_term)\n",
    "# 分别对偶数和奇数位置赋值\n",
    "pe[:, 0::2] = torch.sin(position * div_term)\n",
    "pe[:, 1::2] = torch.cos(position * div_term[:d_model // 2]) \n",
    "pe=pe.unsqueeze(0)#维度变成[batch_size, seq_length, d_model]\n",
    "embedded_sentence + pe[:, :embedded_sentence.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "674bf768",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原张量格式如下： tensor([[[[ 1,  2,  3,  4],\n",
      "          [ 5,  6,  7,  8]],\n",
      "\n",
      "         [[ 9, 10, 11, 12],\n",
      "          [13, 14, 15, 16]],\n",
      "\n",
      "         [[17, 18, 19, 20],\n",
      "          [21, 22, 23, 24]],\n",
      "\n",
      "         [[25, 26, 27, 28],\n",
      "          [29, 30, 31, 32]]],\n",
      "\n",
      "\n",
      "        [[[33, 34, 35, 36],\n",
      "          [37, 38, 39, 40]],\n",
      "\n",
      "         [[41, 42, 43, 44],\n",
      "          [45, 46, 47, 48]],\n",
      "\n",
      "         [[49, 50, 51, 52],\n",
      "          [53, 54, 55, 56]],\n",
      "\n",
      "         [[57, 58, 59, 60],\n",
      "          [61, 62, 63, 64]]]])\n",
      "使用permute后的格式如下： tensor([[[[ 1,  2,  3,  4],\n",
      "          [ 9, 10, 11, 12],\n",
      "          [17, 18, 19, 20],\n",
      "          [25, 26, 27, 28]],\n",
      "\n",
      "         [[ 5,  6,  7,  8],\n",
      "          [13, 14, 15, 16],\n",
      "          [21, 22, 23, 24],\n",
      "          [29, 30, 31, 32]]],\n",
      "\n",
      "\n",
      "        [[[33, 34, 35, 36],\n",
      "          [41, 42, 43, 44],\n",
      "          [49, 50, 51, 52],\n",
      "          [57, 58, 59, 60]],\n",
      "\n",
      "         [[37, 38, 39, 40],\n",
      "          [45, 46, 47, 48],\n",
      "          [53, 54, 55, 56],\n",
      "          [61, 62, 63, 64]]]])\n",
      "使用transpose后的格式如下： tensor([[[[ 1,  2,  3,  4],\n",
      "          [ 9, 10, 11, 12],\n",
      "          [17, 18, 19, 20],\n",
      "          [25, 26, 27, 28]],\n",
      "\n",
      "         [[ 5,  6,  7,  8],\n",
      "          [13, 14, 15, 16],\n",
      "          [21, 22, 23, 24],\n",
      "          [29, 30, 31, 32]]],\n",
      "\n",
      "\n",
      "        [[[33, 34, 35, 36],\n",
      "          [41, 42, 43, 44],\n",
      "          [49, 50, 51, 52],\n",
      "          [57, 58, 59, 60]],\n",
      "\n",
      "         [[37, 38, 39, 40],\n",
      "          [45, 46, 47, 48],\n",
      "          [53, 54, 55, 56],\n",
      "          [61, 62, 63, 64]]]])\n"
     ]
    }
   ],
   "source": [
    "## tips：下面是关于维度转换的测试\n",
    "batch_size = 2\n",
    "seq_length = 4\n",
    "d_model = 8\n",
    "num_heads = 2\n",
    "d_k = d_model // num_heads\n",
    "\n",
    "# 定义输入张量\n",
    "x = torch.tensor([\n",
    "    [\n",
    "        [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "        [9, 10, 11, 12, 13, 14, 15, 16],\n",
    "        [17, 18, 19, 20, 21, 22, 23, 24],\n",
    "        [25, 26, 27, 28, 29, 30, 31, 32]\n",
    "    ],\n",
    "    [\n",
    "        [33, 34, 35, 36, 37, 38, 39, 40],\n",
    "        [41, 42, 43, 44, 45, 46, 47, 48],\n",
    "        [49, 50, 51, 52, 53, 54, 55, 56],\n",
    "        [57, 58, 59, 60, 61, 62, 63, 64]\n",
    "    ]\n",
    "])  # 形状 [2, 4, 8]\n",
    "\n",
    "# 重塑张量\n",
    "x = x.view(batch_size, seq_length, num_heads, d_k)  # [2, 4, 2, 4]\n",
    "print(\"原张量格式如下：\",x)\n",
    "# 调整维度顺序\n",
    "y = x.permute(0, 2, 1, 3)  # [2, 2, 4, 4]\n",
    "# 打印新张量的形状\n",
    "print(\"使用permute后的格式如下：\",y)\n",
    "z = x.transpose(1,2)\n",
    "zz = x.transpose(2,1)\n",
    "print(\"使用transpose后的格式如下：\",z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c1ed97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前向传播成功。\n",
      "所有测试通过！\n",
      "自定义实现与 PyTorch 实现输出匹配。\n"
     ]
    }
   ],
   "source": [
    "## tips：下面是关于多头注意力的测试\n",
    "batch_size = 2\n",
    "seq_length = 4\n",
    "d_model = 8\n",
    "num_heads = 2\n",
    "\n",
    "# 实例化类\n",
    "mha = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "# 创建随机张量\n",
    "Q = torch.randn(batch_size, seq_length, d_model)\n",
    "K = torch.randn(batch_size, seq_length, d_model)\n",
    "V = torch.randn(batch_size, seq_length, d_model)\n",
    "\n",
    "# 测试 split_heads 和 concat_heads\n",
    "split = mha.split_heads(Q)\n",
    "concat = mha.concat_heads(split)\n",
    "assert torch.allclose(Q, concat), \"split_heads 和 concat_heads 不是互逆的。\"\n",
    "\n",
    "# 测试 scaled_dot_product_attention\n",
    "attn_output = mha.dot_attention(split, split, split)\n",
    "expected_shape = (batch_size, num_heads, seq_length, mha.d_k)\n",
    "assert attn_output.shape == expected_shape, f\"Attention 输出形状不正确，期望 {expected_shape}，得到 {attn_output.shape}。\"\n",
    "\n",
    "# 测试 forward 方法\n",
    "output = mha(Q, K, V)\n",
    "expected_shape = (batch_size, seq_length, d_model)\n",
    "assert output.shape == expected_shape, f\"输出形状不正确，期望 {expected_shape}，得到 {output.shape}。\"\n",
    "\n",
    "# 检查是否有运行时错误\n",
    "try:\n",
    "    output = mha(Q, K, V)\n",
    "    print(\"前向传播成功。\")\n",
    "except Exception as e:\n",
    "    print(f\"前向传播时出错：{e}\")\n",
    "\n",
    "# 验证梯度是否正确传播\n",
    "Q.requires_grad_(True)\n",
    "output = mha(Q, K, V)\n",
    "output.mean().backward()\n",
    "assert Q.grad is not None, \"梯度没有回传到 Q。\"\n",
    "\n",
    "print(\"所有测试通过！\")\n",
    "\n",
    "# 与 PyTorch 的实现进行比较\n",
    "torch_mha = nn.MultiheadAttention(embed_dim=d_model, num_heads=num_heads, batch_first=True)\n",
    "\n",
    "# 将自定义 MHA 的权重复制到 PyTorch MHA\n",
    "with torch.no_grad():\n",
    "    torch_mha.in_proj_weight = nn.Parameter(torch.cat([\n",
    "        mha.Qw.weight,\n",
    "        mha.Kw.weight,\n",
    "        mha.Vw.weight\n",
    "    ], dim=0))\n",
    "    torch_mha.in_proj_bias = nn.Parameter(torch.cat([\n",
    "        mha.Qw.bias,\n",
    "        mha.Kw.bias,\n",
    "        mha.Vw.bias\n",
    "    ], dim=0))\n",
    "    torch_mha.out_proj.weight = mha.Ow.weight\n",
    "    torch_mha.out_proj.bias = mha.Ow.bias\n",
    "\n",
    "# 使用 PyTorch 的 MHA\n",
    "torch_output, _ = torch_mha(Q, K, V)\n",
    "\n",
    "# 比较输出\n",
    "if torch.allclose(output, torch_output, atol=1e-6):\n",
    "    print(\"自定义实现与 PyTorch 实现输出匹配。\")\n",
    "else:\n",
    "    print(\"自定义实现与 PyTorch 实现输出不匹配。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3cfc435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchNorm 输出：\n",
      " tensor([[[-1.4639, -1.4639, -1.4639, -1.4639],\n",
      "         [-0.8783, -0.8783, -0.8783, -0.8783],\n",
      "         [-0.2928, -0.2928, -0.2928, -0.2928]],\n",
      "\n",
      "        [[ 0.2928,  0.2928,  0.2928,  0.2928],\n",
      "         [ 0.8783,  0.8783,  0.8783,  0.8783],\n",
      "         [ 1.4639,  1.4639,  1.4639,  1.4639]]], grad_fn=<PermuteBackward0>)\n",
      "LayerNorm 输出：\n",
      " tensor([[[-1.3416, -0.4472,  0.4472,  1.3416],\n",
      "         [-1.3416, -0.4472,  0.4472,  1.3416],\n",
      "         [-1.3416, -0.4472,  0.4472,  1.3416]],\n",
      "\n",
      "        [[-1.3416, -0.4472,  0.4472,  1.3416],\n",
      "         [-1.3416, -0.4472,  0.4472,  1.3416],\n",
      "         [-1.3416, -0.4472,  0.4472,  1.3416]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# tips：下面是关于Norm的测试\n",
    "\n",
    "# 输入张量\n",
    "x = torch.tensor([\n",
    "    [[1.0, 2.0, 3.0, 4.0],\n",
    "     [5.0, 6.0, 7.0, 8.0],\n",
    "     [9.0, 10.0, 11.0, 12.0]],\n",
    "    [[13.0, 14.0, 15.0, 16.0],\n",
    "     [17.0, 18.0, 19.0, 20.0],\n",
    "     [21.0, 22.0, 23.0, 24.0]]\n",
    "])#2，3，4\n",
    "\n",
    "# BatchNorm，假设特征维度为 4\n",
    "batch_norm = nn.BatchNorm1d(num_features=4)\n",
    "x_bn = x.permute(0, 2, 1)  # 将维度调整为 (batch, features, seq)，因为BatchNorm1d默认第一维是特征\n",
    "output_bn = batch_norm(x_bn)\n",
    "x_original = output_bn .permute(0, 2, 1)\n",
    "print(\"BatchNorm 输出：\\n\", x_original)\n",
    "\n",
    "# LayerNorm\n",
    "layer_norm = nn.LayerNorm(normalized_shape=4)\n",
    "output_ln = layer_norm(x)\n",
    "print(\"LayerNorm 输出：\\n\", output_ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c27dcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128, 512])\n"
     ]
    }
   ],
   "source": [
    "# tips：下面是关于FeedForward的测试\n",
    "ffn = FeedForward(512, 2048)\n",
    "input_tensor = torch.randn(32, 128, 512)\n",
    "output_tensor = ffn(input_tensor)\n",
    "print(output_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71f2d1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 10, 8]) tensor([[[0.0794, 0.0961, 0.5199, 0.1447, 0.4845, 0.1571, 0.9381, 0.0380],\n",
      "         [0.6824, 0.5911, 0.5195, 0.2312, 0.6610, 0.0553, 0.1355, 0.8133],\n",
      "         [0.7055, 0.1072, 0.1031, 0.0083, 0.7898, 0.0363, 0.9859, 0.6727],\n",
      "         [0.8179, 0.9442, 0.6649, 0.2351, 0.4148, 0.1439, 0.1616, 0.8135],\n",
      "         [0.2868, 0.4842, 0.0376, 0.9902, 0.6656, 0.3463, 0.6123, 0.3850],\n",
      "         [0.8098, 0.3375, 0.9064, 0.7276, 0.4300, 0.9140, 0.3677, 0.3393],\n",
      "         [0.3026, 0.8928, 0.3511, 0.9797, 0.7104, 0.6702, 0.6883, 0.6142],\n",
      "         [0.1234, 0.9784, 0.9952, 0.5784, 0.6151, 0.3749, 0.3709, 0.4311],\n",
      "         [0.0523, 0.5461, 0.6044, 0.5659, 0.1636, 0.2716, 0.8121, 0.7992],\n",
      "         [0.7991, 0.6313, 0.1010, 0.2889, 0.9361, 0.9229, 0.6558, 0.2678]],\n",
      "\n",
      "        [[0.9345, 0.1184, 0.8892, 0.4870, 0.5273, 0.9957, 0.0352, 0.3515],\n",
      "         [0.2270, 0.8241, 0.6095, 0.7683, 0.8029, 0.4367, 0.1398, 0.4566],\n",
      "         [0.4320, 0.5838, 0.4979, 0.5707, 0.4658, 0.6051, 0.6836, 0.3473],\n",
      "         [0.6497, 0.2450, 0.9724, 0.1880, 0.7374, 0.9682, 0.0446, 0.0477],\n",
      "         [0.8681, 0.1722, 0.1388, 0.4422, 0.7363, 0.2794, 0.3376, 0.2038],\n",
      "         [0.6718, 0.4608, 0.3055, 0.4733, 0.1307, 0.7103, 0.9618, 0.4969],\n",
      "         [0.4668, 0.5078, 0.7534, 0.1895, 0.6560, 0.8268, 0.5930, 0.8038],\n",
      "         [0.8185, 0.5648, 0.8113, 0.3276, 0.7936, 0.1484, 0.8392, 0.8999],\n",
      "         [0.8671, 0.1888, 0.0714, 0.8314, 0.9215, 0.6880, 0.2886, 0.7625],\n",
      "         [0.7582, 0.0521, 0.7103, 0.9207, 0.0749, 0.3231, 0.1982, 0.9058]]])\n",
      "Output shape: torch.Size([2, 10, 8]) tensor([[[-0.9491,  0.6665, -0.7105, -0.8873,  0.5371, -1.0302,  1.9602,\n",
      "           0.4133],\n",
      "         [-0.2170,  0.8215, -0.8049, -1.1717,  0.7680, -1.4437,  0.5309,\n",
      "           1.5169],\n",
      "         [ 0.0790,  0.1433, -1.2026, -1.1258,  0.7019, -1.1820,  1.4068,\n",
      "           1.1793],\n",
      "         [-0.2050,  1.4435, -0.6989, -1.0830, -0.0160, -1.3354,  0.3844,\n",
      "           1.5104],\n",
      "         [-0.8914,  0.9090, -1.8211,  0.4899,  0.4799, -0.9709,  1.0056,\n",
      "           0.7990],\n",
      "         [-0.4886,  0.7678, -1.4184, -1.0342, -0.3884, -0.2210,  1.4881,\n",
      "           1.2947],\n",
      "         [-1.2290,  1.3203, -1.5741,  0.2090,  0.2210, -0.7462,  0.8782,\n",
      "           0.9209],\n",
      "         [-1.5793,  1.7754, -0.0665, -0.5278,  0.2361, -1.1005,  0.5737,\n",
      "           0.6889],\n",
      "         [-1.2966,  1.0405, -0.8089, -0.3059, -0.3852, -0.9005,  1.3210,\n",
      "           1.3356],\n",
      "         [-0.2365,  0.9403, -1.8852, -1.1389,  0.9807, -0.0074,  1.0858,\n",
      "           0.2612]],\n",
      "\n",
      "        [[ 0.4318, -0.4425, -0.7482, -2.0053,  1.2224,  0.3614, -0.0078,\n",
      "           1.1881],\n",
      "         [-1.1656,  1.4829, -1.0913, -0.2621,  0.9136, -1.1346,  0.2604,\n",
      "           0.9966],\n",
      "         [-0.9193,  1.2371, -1.4048, -0.5474,  0.2956, -0.8261,  1.4274,\n",
      "           0.7376],\n",
      "         [-0.5024,  0.5003, -0.0517, -2.1544,  1.6045,  0.4884,  0.1867,\n",
      "          -0.0713],\n",
      "         [ 0.3719,  0.3287, -1.5593, -0.6677,  1.1905, -1.3772,  1.0740,\n",
      "           0.6393],\n",
      "         [-0.3306,  0.8581, -1.5077, -0.7528, -0.4953, -0.3997,  1.7915,\n",
      "           0.8366],\n",
      "         [-0.9932,  0.7109, -0.5906, -1.7234,  0.8180, -0.3634,  0.8530,\n",
      "           1.2886],\n",
      "         [-0.2124,  0.5360, -0.6485, -1.2596,  0.6640, -1.5062,  1.1563,\n",
      "           1.2704],\n",
      "         [ 0.0163,  0.1697, -1.9895, -0.2595,  1.1001, -0.8035,  0.3688,\n",
      "           1.3977],\n",
      "         [ 0.0500, -0.1841, -0.9665,  0.1913, -0.4637, -1.2867,  0.4396,\n",
      "           2.2201]]], grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# tips：下面是关于encoder的测试\n",
    "d_model = 8\n",
    "num_heads = 4\n",
    "d_hidden = 128\n",
    "seq_len = 10\n",
    "batch_size = 2\n",
    "\n",
    "# Initialize the EncoderLayer\n",
    "encoder_layer = EncoderLayer(d_model, num_heads, d_hidden)\n",
    "\n",
    "x = torch.rand(batch_size, seq_len, d_model)\n",
    "\n",
    "# Forward pass through the encoder layer\n",
    "output = encoder_layer(x)\n",
    "\n",
    "# Verify the output shape\n",
    "print(\"Input shape:\", x.shape,x)\n",
    "print(\"Output shape:\", output.shape,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52200c27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fa34ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd28f96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
