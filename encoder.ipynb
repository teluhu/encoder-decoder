{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8fd0db9",
   "metadata": {},
   "source": [
    "总结：首先是Input_embedding和positional_encoding 是Transformer中的一环\n",
    "EncoderLayer包含MultiHeadAttention\n",
    "https://blog.csdn.net/weixin_44613415/article/details/139848359"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c567925a",
   "metadata": {},
   "source": [
    "## 下面是Transformer的class\n",
    "已知这里会有Input_embedding和Positional_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f62c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fc86123",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):#维度是奇数也不会报错\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super().__init__()#继承父类nn.Module\n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        # 只考虑偶数位置，确保 div_term 的长度匹配\n",
    "        div_term = torch.exp(2 * torch.arange(0, (d_model + 1) // 2).float()  * -(math.log(10000.0) / d_model))\n",
    "        #其中2 * torch.arange(0, (d_model + 1) // 2).float()是2i\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term[:d_model // 2]) \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))#pe是[batch_size, seq_length, d_model]，注册后会成为self.pe\n",
    "\n",
    "    def forward(self, x):#这里的x是[batch_size, seq_length, d_model]\n",
    "        return x + self.pe[:, :x.size(1)]#也可以尝试下除了相加的方式，但是感觉乘法的话就会有权重为0的可能性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4df05750",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):#x是[batch_size, seq_length, d_model]\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()#继承父类nn.Module\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = self.d_model//self.num_heads #因为要整除\n",
    "        self.Qw = nn.Linear(d_model, d_model)#加载Q权重\n",
    "        self.Kw = nn.Linear(d_model, d_model)#加载K权重\n",
    "        self.Vw = nn.Linear(d_model, d_model)#加载V权重\n",
    "        self.Ow = nn.Linear(d_model, d_model)#加载V权重\n",
    "        \n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "    #把第一列和第二列交换，也就是seq_length和self.num_heads\n",
    "    #变成了(batch_size, self.num_heads, seq_length, self.d_k)\n",
    "\n",
    "    def concat_heads(self, x):\n",
    "        batch_size, num_heads, seq_length, d_k = x.size()\n",
    "        print(x.transpose(2,1).is_contiguous())\n",
    "        return x.transpose(2,1).reshape(batch_size, seq_length, self.d_model)\n",
    "    \n",
    "    def dot_attention(self, Q, K, V):\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)#首先是K转置，所以要交换最后两列，矩阵相乘\n",
    "        #得到格式为[batch_size,num_heads,seq_length,seq_length]\n",
    "\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)#对最后一维做softmax\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output#得到了(batch_size, self.num_heads, seq_length, self.d_k)\n",
    "\n",
    "    \n",
    "    def forward(self,Q,K,V):#首先第一步是分头，把d_model分解成num_heads\n",
    "        Qa=self.split_heads(self.Qw(Q))\n",
    "        Ka=self.split_heads(self.Kw(K))\n",
    "        Va=self.split_heads(self.Vw(V))\n",
    "        attn_output = self.dot_attention(Qa, Ka, Va)\n",
    "        output= self.Ow(self.concat_heads(attn_output))\n",
    "        return output\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d1b8a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):# 感觉前馈层能做很多，加上dropout吧\n",
    "    def __init__(self, d_model,d_hidden,is_drop = True, drop = 0.1):\n",
    "        super().__init__()#继承父类nn.Module\n",
    "        self.W1 = nn.Linear(d_model, d_hidden)\n",
    "        self.W2 = nn.Linear(d_hidden, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(drop)\n",
    "        self.is_drop=is_drop\n",
    "    \n",
    "    def forward(self, x,):\n",
    "        x = self.relu(self.W1(x))\n",
    "        if self.is_drop:\n",
    "            x=self.dropout(x)\n",
    "        return self.W2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "712ef3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self,d_model, num_heads, d_hidden,is_drop = True, drop = 0.1):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.feed_forward = FeedForward(d_model,d_hidden,is_drop, drop)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_output = self.attn(x, x, x)\n",
    "        x = self.norm1(x + attn_output)\n",
    "        f_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + f_output)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd6d83f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        #Embedding层输入（vocab表，embedding的维度），输出（句子的长度，embedding的维度）\n",
    "        self.encoder_input_embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        #PositionalEncoding层输入（最大长度，嵌入维度）先把位置编码固定了\n",
    "        self.positional_encoding = PositionalEncoding(max_seq_length, embedding_dim)#位置编码的维度和嵌入维度通常要一样，因为要相加在一起\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7276d249",
   "metadata": {},
   "source": [
    "# 测试部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "679e2768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始句子: ['I', 'like', 'to', 'learn', 'deep', 'learning', 'with', 'PyTorch']\n",
      "句子索引: tensor([[0, 1, 2, 3, 4, 5, 6, 7]])\n",
      "嵌入向量形状: torch.Size([1, 8, 6])\n",
      "嵌入向量:\n",
      " tensor([[[ 0.4043, -1.2915, -0.2429, -0.8538,  0.8766, -0.2860],\n",
      "         [ 2.2470, -0.2905,  1.2139, -0.4224, -2.3051,  0.5736],\n",
      "         [ 1.6440,  0.5960, -0.7766,  1.4761,  0.7996, -0.7448],\n",
      "         [ 0.4901, -0.6855, -1.3334,  0.3146, -1.2906, -0.6187],\n",
      "         [-1.3524,  0.5410, -0.0563, -1.9868,  0.0878, -0.5629],\n",
      "         [ 0.2487,  0.0333, -0.4688,  0.1948,  0.0832,  1.1684],\n",
      "         [ 1.7445,  0.3346, -0.4943, -1.2009, -0.1155, -1.5213],\n",
      "         [-0.1353,  1.1006,  0.0872,  0.6857, -0.9210,  1.6237]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## tips：下面是关于embedding层的测试\n",
    "# 定义词汇表（Vocabulary）\n",
    "vocab = {'I': 0, 'like': 1, 'to': 2, 'learn': 3, 'deep': 4, 'learning': 5, 'with': 6, 'PyTorch': 7}\n",
    "vocab_size = len(vocab)\n",
    "# 定义句子\n",
    "sentence = ['I', 'like', 'to', 'learn', 'deep', 'learning', 'with', 'PyTorch']\n",
    "\n",
    "# 将句子中的单词映射为索引序列\n",
    "sentence_indices = [vocab[word] for word in sentence]\n",
    "# 将索引序列转换为张量，同事\n",
    "sentence_tensor = torch.tensor(sentence_indices).unsqueeze(0) \n",
    "# 定义 nn.Embedding 层\n",
    "embedding_dim = 6\n",
    "embedding_layer = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "# 使用 nn.Embedding 将索引序列转换为嵌入向量\n",
    "embedded_sentence = embedding_layer(sentence_tensor)\n",
    "# 打印结果\n",
    "print(\"原始句子:\", sentence)\n",
    "print(\"句子索引:\", sentence_tensor )\n",
    "print(\"嵌入向量形状:\", embedded_sentence.shape)  # (sequence_length, embedding_dim)\n",
    "print(\"嵌入向量:\\n\", embedded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fb5a03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4043, -0.2915, -0.2429,  0.1462,  0.8766,  0.7140],\n",
       "         [ 3.0884,  0.2498,  1.2603,  0.5765, -2.3030,  1.5736],\n",
       "         [ 2.5533,  0.1799, -0.6839,  2.4718,  0.8039,  0.2551],\n",
       "         [ 0.6312, -1.6755, -1.1946,  1.3049, -1.2842,  0.3813],\n",
       "         [-2.1092, -0.1126,  0.1283, -1.0040,  0.0964,  0.4371],\n",
       "         [-0.7103,  0.3170, -0.2388,  1.1679,  0.0939,  2.1683],\n",
       "         [ 1.4651,  1.2947, -0.2194, -0.2394, -0.1026, -0.5214],\n",
       "         [ 0.5217,  1.8545,  0.4064,  1.6334, -0.9059,  2.6236]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## tips：下面是关于positional embedding层的测试\n",
    "max_seq_length = 10\n",
    "d_model = 6\n",
    "pe = torch.zeros(max_seq_length, d_model)\n",
    "position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "# 只考虑偶数位置，确保 div_term 的长度匹配\n",
    "div_term = torch.exp(2*torch.arange(0, (d_model + 1) // 2).float()  * -(math.log(10000.0) / d_model))\n",
    "# print(position)\n",
    "# print(torch.arange(0, (d_model + 1) // 2).float(), div_term)\n",
    "# 分别对偶数和奇数位置赋值\n",
    "pe[:, 0::2] = torch.sin(position * div_term)\n",
    "pe[:, 1::2] = torch.cos(position * div_term[:d_model // 2]) \n",
    "pe=pe.unsqueeze(0)#维度变成[batch_size, seq_length, d_model]\n",
    "embedded_sentence + pe[:, :embedded_sentence.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "674bf768",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原张量格式如下： tensor([[[[ 1,  2,  3,  4],\n",
      "          [ 5,  6,  7,  8]],\n",
      "\n",
      "         [[ 9, 10, 11, 12],\n",
      "          [13, 14, 15, 16]],\n",
      "\n",
      "         [[17, 18, 19, 20],\n",
      "          [21, 22, 23, 24]],\n",
      "\n",
      "         [[25, 26, 27, 28],\n",
      "          [29, 30, 31, 32]]],\n",
      "\n",
      "\n",
      "        [[[33, 34, 35, 36],\n",
      "          [37, 38, 39, 40]],\n",
      "\n",
      "         [[41, 42, 43, 44],\n",
      "          [45, 46, 47, 48]],\n",
      "\n",
      "         [[49, 50, 51, 52],\n",
      "          [53, 54, 55, 56]],\n",
      "\n",
      "         [[57, 58, 59, 60],\n",
      "          [61, 62, 63, 64]]]])\n",
      "使用permute后的格式如下： tensor([[[[ 1,  2,  3,  4],\n",
      "          [ 9, 10, 11, 12],\n",
      "          [17, 18, 19, 20],\n",
      "          [25, 26, 27, 28]],\n",
      "\n",
      "         [[ 5,  6,  7,  8],\n",
      "          [13, 14, 15, 16],\n",
      "          [21, 22, 23, 24],\n",
      "          [29, 30, 31, 32]]],\n",
      "\n",
      "\n",
      "        [[[33, 34, 35, 36],\n",
      "          [41, 42, 43, 44],\n",
      "          [49, 50, 51, 52],\n",
      "          [57, 58, 59, 60]],\n",
      "\n",
      "         [[37, 38, 39, 40],\n",
      "          [45, 46, 47, 48],\n",
      "          [53, 54, 55, 56],\n",
      "          [61, 62, 63, 64]]]])\n",
      "使用transpose后的格式如下： tensor([[[[ 1,  2,  3,  4],\n",
      "          [ 9, 10, 11, 12],\n",
      "          [17, 18, 19, 20],\n",
      "          [25, 26, 27, 28]],\n",
      "\n",
      "         [[ 5,  6,  7,  8],\n",
      "          [13, 14, 15, 16],\n",
      "          [21, 22, 23, 24],\n",
      "          [29, 30, 31, 32]]],\n",
      "\n",
      "\n",
      "        [[[33, 34, 35, 36],\n",
      "          [41, 42, 43, 44],\n",
      "          [49, 50, 51, 52],\n",
      "          [57, 58, 59, 60]],\n",
      "\n",
      "         [[37, 38, 39, 40],\n",
      "          [45, 46, 47, 48],\n",
      "          [53, 54, 55, 56],\n",
      "          [61, 62, 63, 64]]]])\n"
     ]
    }
   ],
   "source": [
    "## tips：下面是关于维度转换的测试\n",
    "batch_size = 2\n",
    "seq_length = 4\n",
    "d_model = 8\n",
    "num_heads = 2\n",
    "d_k = d_model // num_heads\n",
    "\n",
    "# 定义输入张量\n",
    "x = torch.tensor([\n",
    "    [\n",
    "        [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "        [9, 10, 11, 12, 13, 14, 15, 16],\n",
    "        [17, 18, 19, 20, 21, 22, 23, 24],\n",
    "        [25, 26, 27, 28, 29, 30, 31, 32]\n",
    "    ],\n",
    "    [\n",
    "        [33, 34, 35, 36, 37, 38, 39, 40],\n",
    "        [41, 42, 43, 44, 45, 46, 47, 48],\n",
    "        [49, 50, 51, 52, 53, 54, 55, 56],\n",
    "        [57, 58, 59, 60, 61, 62, 63, 64]\n",
    "    ]\n",
    "])  # 形状 [2, 4, 8]\n",
    "\n",
    "# 重塑张量\n",
    "x = x.view(batch_size, seq_length, num_heads, d_k)  # [2, 4, 2, 4]\n",
    "print(\"原张量格式如下：\",x)\n",
    "# 调整维度顺序\n",
    "y = x.permute(0, 2, 1, 3)  # [2, 2, 4, 4]\n",
    "# 打印新张量的形状\n",
    "print(\"使用permute后的格式如下：\",y)\n",
    "z = x.transpose(1,2)\n",
    "zz = x.transpose(2,1)\n",
    "print(\"使用transpose后的格式如下：\",z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c1ed97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "前向传播成功。\n",
      "False\n",
      "所有测试通过！\n",
      "自定义实现与 PyTorch 实现输出匹配。\n"
     ]
    }
   ],
   "source": [
    "## tips：下面是关于多头注意力的测试\n",
    "batch_size = 2\n",
    "seq_length = 4\n",
    "d_model = 8\n",
    "num_heads = 2\n",
    "\n",
    "# 实例化类\n",
    "mha = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "# 创建随机张量\n",
    "Q = torch.randn(batch_size, seq_length, d_model)\n",
    "K = torch.randn(batch_size, seq_length, d_model)\n",
    "V = torch.randn(batch_size, seq_length, d_model)\n",
    "\n",
    "# 测试 split_heads 和 concat_heads\n",
    "split = mha.split_heads(Q)\n",
    "concat = mha.concat_heads(split)\n",
    "assert torch.allclose(Q, concat), \"split_heads 和 concat_heads 不是互逆的。\"\n",
    "\n",
    "# 测试 scaled_dot_product_attention\n",
    "attn_output = mha.dot_attention(split, split, split)\n",
    "expected_shape = (batch_size, num_heads, seq_length, mha.d_k)\n",
    "assert attn_output.shape == expected_shape, f\"Attention 输出形状不正确，期望 {expected_shape}，得到 {attn_output.shape}。\"\n",
    "\n",
    "# 测试 forward 方法\n",
    "output = mha(Q, K, V)\n",
    "expected_shape = (batch_size, seq_length, d_model)\n",
    "assert output.shape == expected_shape, f\"输出形状不正确，期望 {expected_shape}，得到 {output.shape}。\"\n",
    "\n",
    "# 检查是否有运行时错误\n",
    "try:\n",
    "    output = mha(Q, K, V)\n",
    "    print(\"前向传播成功。\")\n",
    "except Exception as e:\n",
    "    print(f\"前向传播时出错：{e}\")\n",
    "\n",
    "# 验证梯度是否正确传播\n",
    "Q.requires_grad_(True)\n",
    "output = mha(Q, K, V)\n",
    "output.mean().backward()\n",
    "assert Q.grad is not None, \"梯度没有回传到 Q。\"\n",
    "\n",
    "print(\"所有测试通过！\")\n",
    "\n",
    "# 与 PyTorch 的实现进行比较\n",
    "torch_mha = nn.MultiheadAttention(embed_dim=d_model, num_heads=num_heads, batch_first=True)\n",
    "\n",
    "# 将自定义 MHA 的权重复制到 PyTorch MHA\n",
    "with torch.no_grad():\n",
    "    torch_mha.in_proj_weight = nn.Parameter(torch.cat([\n",
    "        mha.Qw.weight,\n",
    "        mha.Kw.weight,\n",
    "        mha.Vw.weight\n",
    "    ], dim=0))\n",
    "    torch_mha.in_proj_bias = nn.Parameter(torch.cat([\n",
    "        mha.Qw.bias,\n",
    "        mha.Kw.bias,\n",
    "        mha.Vw.bias\n",
    "    ], dim=0))\n",
    "    torch_mha.out_proj.weight = mha.Ow.weight\n",
    "    torch_mha.out_proj.bias = mha.Ow.bias\n",
    "\n",
    "# 使用 PyTorch 的 MHA\n",
    "torch_output, _ = torch_mha(Q, K, V)\n",
    "\n",
    "# 比较输出\n",
    "if torch.allclose(output, torch_output, atol=1e-6):\n",
    "    print(\"自定义实现与 PyTorch 实现输出匹配。\")\n",
    "else:\n",
    "    print(\"自定义实现与 PyTorch 实现输出不匹配。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3cfc435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchNorm 输出：\n",
      " tensor([[[-1.4639, -1.4639, -1.4639, -1.4639],\n",
      "         [-0.8783, -0.8783, -0.8783, -0.8783],\n",
      "         [-0.2928, -0.2928, -0.2928, -0.2928]],\n",
      "\n",
      "        [[ 0.2928,  0.2928,  0.2928,  0.2928],\n",
      "         [ 0.8783,  0.8783,  0.8783,  0.8783],\n",
      "         [ 1.4639,  1.4639,  1.4639,  1.4639]]], grad_fn=<PermuteBackward0>)\n",
      "LayerNorm 输出：\n",
      " tensor([[[-1.3416, -0.4472,  0.4472,  1.3416],\n",
      "         [-1.3416, -0.4472,  0.4472,  1.3416],\n",
      "         [-1.3416, -0.4472,  0.4472,  1.3416]],\n",
      "\n",
      "        [[-1.3416, -0.4472,  0.4472,  1.3416],\n",
      "         [-1.3416, -0.4472,  0.4472,  1.3416],\n",
      "         [-1.3416, -0.4472,  0.4472,  1.3416]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# tips：下面是关于Norm的测试\n",
    "\n",
    "# 输入张量\n",
    "x = torch.tensor([\n",
    "    [[1.0, 2.0, 3.0, 4.0],\n",
    "     [5.0, 6.0, 7.0, 8.0],\n",
    "     [9.0, 10.0, 11.0, 12.0]],\n",
    "    [[13.0, 14.0, 15.0, 16.0],\n",
    "     [17.0, 18.0, 19.0, 20.0],\n",
    "     [21.0, 22.0, 23.0, 24.0]]\n",
    "])#2，3，4\n",
    "\n",
    "# BatchNorm，假设特征维度为 4\n",
    "batch_norm = nn.BatchNorm1d(num_features=4)\n",
    "x_bn = x.permute(0, 2, 1)  # 将维度调整为 (batch, features, seq)，因为BatchNorm1d默认第一维是特征\n",
    "output_bn = batch_norm(x_bn)\n",
    "x_original = output_bn .permute(0, 2, 1)\n",
    "print(\"BatchNorm 输出：\\n\", x_original)\n",
    "\n",
    "# LayerNorm\n",
    "layer_norm = nn.LayerNorm(normalized_shape=4)\n",
    "output_ln = layer_norm(x)\n",
    "print(\"LayerNorm 输出：\\n\", output_ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c27dcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128, 512])\n"
     ]
    }
   ],
   "source": [
    "# tips：下面是关于FeedForward的测试\n",
    "ffn = FeedForward(512, 2048)\n",
    "input_tensor = torch.randn(32, 128, 512)\n",
    "output_tensor = ffn(input_tensor)\n",
    "print(output_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71f2d1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Input shape: torch.Size([2, 10, 8]) tensor([[[0.5790, 0.0260, 0.3102, 0.0663, 0.6011, 0.5780, 0.1035, 0.8055],\n",
      "         [0.0926, 0.1098, 0.7685, 0.5787, 0.3136, 0.9057, 0.3629, 0.8039],\n",
      "         [0.6538, 0.4667, 0.6089, 0.5129, 0.5497, 0.6590, 0.8774, 0.4208],\n",
      "         [0.5561, 0.4058, 0.4065, 0.3415, 0.8699, 0.4529, 0.4933, 0.7936],\n",
      "         [0.7680, 0.8520, 0.5793, 0.2207, 0.7538, 0.7301, 0.3925, 0.7629],\n",
      "         [0.3353, 0.7196, 0.4278, 0.0863, 0.5896, 0.0084, 0.1123, 0.0618],\n",
      "         [0.9666, 0.2721, 0.8467, 0.9735, 0.0580, 0.6901, 0.5099, 0.0811],\n",
      "         [0.1215, 0.6658, 0.0559, 0.7967, 0.3370, 0.4353, 0.3254, 0.0485],\n",
      "         [0.5492, 0.3599, 0.6164, 0.5901, 0.4888, 0.7835, 0.3064, 0.2091],\n",
      "         [0.3789, 0.5891, 0.7772, 0.2430, 0.0946, 0.4043, 0.7638, 0.4567]],\n",
      "\n",
      "        [[0.4726, 0.4620, 0.7999, 0.2413, 0.4103, 0.8793, 0.2225, 0.7576],\n",
      "         [0.1452, 0.5385, 0.3689, 0.2747, 0.6563, 0.0144, 0.5069, 0.9782],\n",
      "         [0.1159, 0.9666, 0.8609, 0.1180, 0.5089, 0.9220, 0.0407, 0.8146],\n",
      "         [0.1725, 0.9399, 0.4261, 0.4555, 0.2044, 0.9033, 0.8771, 0.6245],\n",
      "         [0.7776, 0.7776, 0.8758, 0.7256, 0.1397, 0.1907, 0.3671, 0.7879],\n",
      "         [0.6535, 0.7388, 0.3815, 0.5394, 0.2120, 0.1611, 0.6108, 0.9861],\n",
      "         [0.9265, 0.7390, 0.4362, 0.8915, 0.7183, 0.4983, 0.1816, 0.7526],\n",
      "         [0.4676, 0.4646, 0.4260, 0.6028, 0.2209, 0.4347, 0.9038, 0.6397],\n",
      "         [0.9655, 0.8456, 0.2269, 0.5551, 0.4272, 0.9421, 0.8205, 0.4268],\n",
      "         [0.3861, 0.0018, 0.3161, 0.9924, 0.8623, 0.3447, 0.7107, 0.5608]]])\n",
      "Output shape: torch.Size([2, 10, 8]) tensor([[[ 0.7211, -1.1158, -1.2425, -0.9789,  1.3051,  1.4216, -0.0193,\n",
      "          -0.0913],\n",
      "         [-0.4584, -0.9588, -0.5594, -0.2012,  0.0303,  2.3963,  0.4851,\n",
      "          -0.7338],\n",
      "         [ 0.7673, -0.5925, -0.9219, -0.5004,  0.4949,  1.1981,  1.2230,\n",
      "          -1.6684],\n",
      "         [ 0.6065, -0.5714, -1.5227, -0.8531,  1.6572,  0.9595,  0.3883,\n",
      "          -0.6642],\n",
      "         [ 1.0185,  0.4293, -1.5369, -1.1040,  1.0762,  1.0983, -0.0716,\n",
      "          -0.9098],\n",
      "         [ 0.7282,  0.8453, -0.9356, -0.7203,  1.6211,  0.0436,  0.0689,\n",
      "          -1.6511],\n",
      "         [ 1.4225, -0.7561, -0.3344,  0.5609, -0.4250,  1.0612,  0.3540,\n",
      "          -1.8831],\n",
      "         [-0.0320,  0.7310, -1.6212,  0.9187,  0.5047,  0.8904,  0.2982,\n",
      "          -1.6899],\n",
      "         [ 0.6634, -0.4135, -0.9148,  0.0758,  0.6845,  1.5779,  0.2093,\n",
      "          -1.8826],\n",
      "         [ 0.7031,  0.3118, -0.7264, -1.1590, -0.1974,  0.8474,  1.6524,\n",
      "          -1.4318]],\n",
      "\n",
      "        [[ 0.6666, -0.0448, -0.8764, -1.1446,  0.3480,  2.0847, -0.0299,\n",
      "          -1.0037],\n",
      "         [-0.2055,  0.4236, -1.7456, -1.0124,  1.5698,  0.0807,  1.0928,\n",
      "          -0.2034],\n",
      "         [-0.2766,  1.1386, -0.9100, -1.2026,  0.4892,  1.8569, -0.3676,\n",
      "          -0.7280],\n",
      "         [-0.1216,  0.9208, -1.6954, -0.1663, -0.1501,  1.2618,  1.1197,\n",
      "          -1.1690],\n",
      "         [ 1.9410,  0.9066, -1.2168, -0.0805, -0.4224,  0.0825,  0.1040,\n",
      "          -1.3143],\n",
      "         [ 0.9346,  0.8462, -2.2888, -0.3023,  0.0926,  0.0842,  0.9740,\n",
      "          -0.3405],\n",
      "         [ 1.1003,  0.2711, -1.9228,  0.3079,  1.1082,  0.6710, -0.5861,\n",
      "          -0.9496],\n",
      "         [ 0.7278, -0.1352, -1.7492, -0.3230,  0.1282,  0.7935,  1.5992,\n",
      "          -1.0413],\n",
      "         [ 1.0062,  0.4521, -1.8305, -0.2776,  0.2480,  0.9489,  0.7857,\n",
      "          -1.3327],\n",
      "         [ 0.2822, -1.2603, -1.2662,  0.4230,  1.2789,  0.5973,  1.1030,\n",
      "          -1.1579]]], grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# tips：下面是关于encoder的测试\n",
    "d_model = 8\n",
    "num_heads = 4\n",
    "d_hidden = 128\n",
    "seq_len = 10\n",
    "batch_size = 2\n",
    "\n",
    "# Initialize the EncoderLayer\n",
    "encoder_layer = EncoderLayer(d_model, num_heads, d_hidden)\n",
    "\n",
    "x = torch.rand(batch_size, seq_len, d_model)\n",
    "\n",
    "# Forward pass through the encoder layer\n",
    "output = encoder_layer(x)\n",
    "\n",
    "# Verify the output shape\n",
    "print(\"Input shape:\", x.shape,x)\n",
    "print(\"Output shape:\", output.shape,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52200c27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fa34ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd28f96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
